{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4974754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8abbdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialDataset(Dataset):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        n_locs = inputs.shape[0] # number of (x,y) positions.\n",
    "        n_contexts = outputs.shape[1]\n",
    "        context_onehots = torch.eye(n_contexts).float()\n",
    "        self.outputs = outputs.T.ravel().reshape(-1,1).float()\n",
    "        self.inputs = inputs.repeat_interleave(n_contexts, dim=0)\n",
    "        self.contexts = context_onehots.repeat_interleave(n_locs, dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.contexts[idx], self.outputs[idx]\n",
    "    \n",
    "    \n",
    "class SpatialModel(nn.Module):\n",
    "    def __init__(self, n_contexts=100):\n",
    "        super().__init__()\n",
    "        self.ctxt_ind = nn.Linear(2, 16)\n",
    "        self.ctxt = nn.Linear(n_contexts, 16, bias=False)\n",
    "        self.ctxt_dep = nn.Linear(32, 16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        ctxt_indep_rep = F.relu(self.ctxt_ind(x))\n",
    "        ctxt_rep = F.relu(self.ctxt(context))\n",
    "        ctxt_dep_rep = F.relu(self.ctxt_dep(torch.hstack([ctxt_indep_rep, ctxt_rep])))\n",
    "        return torch.sigmoid(self.out(ctxt_dep_rep))\n",
    "    \n",
    "    def loss(self, out, ys):\n",
    "        return F.binary_cross_entropy(out, ys)\n",
    "    \n",
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (xs, tcs, ys) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        xs, tcs, ys = xs.to(device), tcs.to(device), ys.to(device)\n",
    "        out = model(xs, tcs)\n",
    "        loss = model.loss(out, ys)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (xs, tcs, ys) in enumerate(test_loader):\n",
    "            xs, tcs, ys = xs.to(device), tcs.to(device), ys.to(device)\n",
    "            out = model(xs, tcs)\n",
    "            loss = model.loss(out, ys)\n",
    "            test_loss += loss.item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "    return test_loss\n",
    "\n",
    "\n",
    "def setup(n_contexts=80, batch_size=512, use_gpu=True, lr=1e-3):\n",
    "    use_cuda = use_gpu and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    inputs = torch.load('../data/spatial_inputs.pt')\n",
    "    outputs = torch.load('../data/spatial_outputs.pt')[:, :n_contexts]\n",
    "    train_dataset = SpatialDataset(inputs, outputs)\n",
    "    train_loader = train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    #### COULD SET UP TEST DATASET HERE ####\n",
    "    model = SpatialModel(n_contexts=n_contexts)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, train_loader, optimizer, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5ff401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train set average loss: 0.00127853\n",
      "Epoch 1 train set average loss: 0.00125425\n",
      "Epoch 2 train set average loss: 0.00123302\n",
      "Epoch 3 train set average loss: 0.00122800\n",
      "Epoch 4 train set average loss: 0.00122670\n",
      "Epoch 5 train set average loss: 0.00122591\n",
      "Epoch 6 train set average loss: 0.00122522\n",
      "Epoch 7 train set average loss: 0.00122458\n",
      "Epoch 8 train set average loss: 0.00122407\n",
      "Epoch 9 train set average loss: 0.00122328\n",
      "Epoch 10 train set average loss: 0.00122256\n",
      "Epoch 11 train set average loss: 0.00122205\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([nepochs])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nepochs):\n\u001b[0;32m----> 7\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     train_losses[iepoch] \u001b[38;5;241m=\u001b[39m train_loss\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iepoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer)\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     36\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (xs, tcs, ys) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     39\u001b[0m     xs, tcs, ys \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mto(device), tcs\u001b[38;5;241m.\u001b[39mto(device), ys\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup the environment.\n",
    "model, train_loader, optimizer, device = setup()\n",
    "\n",
    "nepochs = 100\n",
    "log_interval = 1\n",
    "train_losses = torch.zeros([nepochs])\n",
    "for iepoch in range(nepochs):\n",
    "    train_loss = train(model, device, train_loader, optimizer)\n",
    "    train_losses[iepoch] = train_loss\n",
    "    if iepoch%log_interval==0:\n",
    "        print(f'Epoch {iepoch} train set average loss: {train_loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca58686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329e265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96413621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab9c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d88586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, sharex=True, sharey=True, tight_layout=True, figsize=(20,20))\n",
    "test = cosine_similarity(all_gradients)\n",
    "plt.imshow(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
